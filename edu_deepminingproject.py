# -*- coding: utf-8 -*-
"""Edu_DeepMiningProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/135bcfYIdORz2zY-zNe4OzMvMN4xd33tz

### **1- VERİ ÖN İŞLEME ADIMLARI**

**Gerekli kütüphanelerin yüklenmesi**
"""

# Commented out IPython magic to ensure Python compatibility.
#Gerekli kütphanelerin yüklenmesi
import numpy as np
import pandas as pd
import matplotlib.pylab as plt
import seaborn as sns
import missingno as msno
from scipy import stats
# %matplotlib inline

# Model kütüphanelerinin yüklenmesi
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import cross_val_score

"""**Veri setini yükleme ve bir kopyasını oluşturma:**  

-Veri setini GitHub sayfam üzerinden Colab'a yükleme işlemi.

-Veri setinin bir kopyasını almak ve bununla orijinal veriyi bozmadan işlemler yapma.

-Veri setinin ilk 5 satırını görüntüleme.
"""

all_data = pd.read_csv("https://raw.githubusercontent.com/ulkuhos/Data_Mining_Project/refs/heads/main/Expanded_data_with_more_features.csv", index_col=0)

#Veri setinin bir kopyasını oluşturma:
all_data_copy = all_data.copy()

#Veri setinin ilk 5 satırını görüntüleme:
all_data_copy.head()

#Colab dan veri seti indirme

# Download the dataframe to a CSV file.
from google.colab import files
all_data_copy.to_csv('Expanded_data_with_more_features.csv', encoding = 'utf-8-sig')
files.download('Expanded_data_with_more_features.csv')

"""**Veri setinin genel yapısını öğrenme:**

-Satır/sütun sayıları, öznitelikler, veri yapısı hakkında genel bilgiler yer almaktadır.
"""

all_data_copy.info()

"""**Veri seti boyutunu öğrenme:**

Veri setimizde 14 sütun ve 30641 satır yer aldığını görüyoruz. Bunlardan 14 sütun, 4'ü numeric(float64, int64) ve 10'u kategoriktir.
"""

all_data_copy.shape

# Sayısal öznitelikleri öğrenme:
all_data_copy.describe()

# Kategorik öznitelikleri öğrenme:
all_data_copy.describe(include='object')

"""**DataFrame'deki eksik değerleri (missing values) kontrol etme ve her sütundaki eksik değerlerin sayısını yazdırma:**

-Veri setindeki sütunlarda eksik değer ( NaN) olup olmadığını kontrol ederiz.

-Her sütunda kaç tane eksik değer olduğunu hesaplar ve bu bilgiyi ekrana yazdırırız.Eksik değer yoksa sütun atlanır.
"""

#Sütunlardaki eksik değerleri kontrol etme:
for col in list(all_data_copy.columns):
    if all_data_copy[col].isna().any():
        print(f"{col} has {all_data_copy[col].isna().sum()} missing values")

"""**DataFrame'deki her sütundaki eksik değerlerin (missing values) yüzdesini hesaplama ve bunu ekrana yazdırma:**

-Veri setindeki sütunlarda eksik değer (NaN) olup olmadığını kontrol ederiz.
Eğer bir sütunda eksik değer varsa, eksik değerlerin toplam veri sayısına oranını yüzde olarak hesaplarız.

-Her sütunun eksik veri yüzdesini ekrana yazdırırız.
"""

#Her sütunun eksik veri yüzdesini ekrana yazdırma:
for col in list(all_data_copy.columns):
    if all_data_copy[col].isna().any():
        print(f"{col} : {(all_data_copy[col].isna().sum())/len(all_data_copy[col]) * 100}% missing values")

"""**Eksik Veriyi Görselleştirme:**

-missingno (msno) kütüphanesi kullanılarak veri setindeki eksik değerlerin (NaN) görselleştirilmesini sağlarız.

-Eksik veri analizi için veri setinin sütun bazında eksiklik oranını bir çubuk grafiği (bar chart) olarak gösteririz.

-Keşifsel Veri Analizi (EDA):Veri setinin genel durumu ve eksikliklerin dağılımı hakkında hızlıca fikir edinmemizde bize yardımcı olur. Bu sütunları belirleyerek temizleme stratejisi geliştirilebiliriz.
"""

#msno ile eksik değerleri grafik ile görselleştirme:
msno.bar(figsize=(14, 5), df=all_data_copy, color="purple")
plt.title("Eksik olmayan değerlerin oranı")

"""**Burada**; MathScore adlı hedef değişkenin (target variable) dağılımını ve temel istatistiksel özelliklerini görselleştirmek için üç farklı grafik oluştururuz. Bu, değişkenin veri yapısını anlamamız ve analiz için hazırlık yapmak açısından önemlidir.
Çizdirdiğimiz grafikler ve açıklamaları:


1.   Histogram ve Yoğunluk Grafiği (kde): Veri dağılımını incelemek.
2.   Boxplot: Aykırı değerleri (outliers) ve veri setinin temel istatistiksel özetini görmek.
3.   Q-Q Plot: Veri setinin normal dağılıma uyup uymadığını test etmek.

"""

# Matematik Puanlarının(MathScore değişkeni) Grafiklerle Görselleştirilmesi:

plt.figure(figsize=(15, 5))

plt.subplot(131)
sns.histplot(data=all_data_copy, x="MathScore", kde=True)
plt.title("Distribution of MathScore")

plt.subplot(132)
sns.boxplot(data=all_data_copy, y="MathScore")
plt.title("Box plot of MathScore")

plt.subplot(133)
stats.probplot(all_data_copy["MathScore"], plot=plt, dist='norm')

plt.tight_layout()
plt.show()

"""**Grafiklerin açıklaması:**

Yukarıdaki grafiklerde görüldüğü gibi hedef değişken sola doğru çarpıktır.  Hedef değişkenin sola doğru çarpık (negatively skewed) olduğunu söylemek, veri dağılımının sol tarafa doğru (daha düşük değerlere) uzadığını ve sağ tarafta (daha yüksek değerlerde) yoğunlaştığını ifade eder. Bu durum, dağılımın asimetrik olduğunu ve veri değerlerinin büyük bir kısmının yüksek değerlere odaklandığını gösterir.

**-Buradan, öğrencilerin çoğunun matematikte yüksek performans gösterdiğini ve çok az öğrencinin düşük aldığını çıkarabiliriz.**

-Veri setindeki çarpıklık, bazı algoritmaların (örneğin, doğrusal regresyon gibi) performansını etkileyebilir.

**Sonuç olarak;**

1-Random Forest gibi algoritmalar çarpık veri dağılımlarında bize daha iyi performans gösterebilir.

2-Normalizasyon: Modelleme öncesi veriyi yeniden ölçeklendirmek (normalizasyon) çalışmamız da faydalı olabilir.
"""

# Kategorik ve sayısal değişkenlere ait sütunlar

num_cols = []
cat_cols = []

for col in all_data_copy.columns:
    if all_data_copy[col].dtype != 'object':
        num_cols.append(col)
    else:
        cat_cols.append(col)
print("Categorical features:", cat_cols)
print("Numerical features:", num_cols)

"""DataFrame'deki sütunları, veri türlerine (dtypes) göre kategorik (categorical) ve sayısal (numerical) olarak iki gruba ayırdık. Veriyi daha iyi anlamak ve farklı türdeki sütunlara uygun analizler yapmak için bunu kullanıyoruz."""

#Sayısal sütunlar arası Korelesyon(ilişki) matrisi hesaplama:

correlation_matrix = all_data_copy.corr(numeric_only=True)
print(correlation_matrix["MathScore"].sort_values(ascending=False))

"""DataFrame'deki sayısal sütunlar arasındaki korelasyon matrisini hesaplayadık.MathScore değişkeni ile diğer sayısal değişkenler arasındaki korelasyonları sıraladık. Böylece hedef değişkenimiz olan MathScore üzerindeki etkisi en büyük olan değişkenleri belirleriz. İstersek bunu çıkarabiliriz.

Korelasyon katsayısı, iki değişken arasındaki doğrusal ilişkiyi ölçer ve -1 ile 1 arasında bir değer alır:

*1: Pozitif doğrusal ilişki (bir değişken artarken diğeri de artar).

*−1: Negatif doğrusal ilişki (bir değişken artarken diğeri azalır).

*0: Hiçbir doğrusal ilişki yok demektir.

-MathScore ile kendisi arasındaki korelasyon 1.0'dır (tam ilişki var demektir).

-WritingScore (0.807) ve ReadingScore (0.817), MathScore ile çok güçlü pozitif korelasyona sahiptir.

-NrSiblings ile MathScore arasında negatif yönde ve ilişki düşüktür (korelasyon katsayısı -0.001).

### **Grafiklerle Değişkenler Arasındaki İlişikilerin İncelenmesi:**

**1- MathScore hedef değişkeni ile diğer sayısal değişkenler arasındaki ilişkiler:**
"""

#MathScore hedef değişkeni ile diğer sayısal değişkenler arasındaki ilişki:

plt.figure(figsize=(12,4))

plt.subplot(131)
sns.regplot(x=all_data_copy["ReadingScore"], y=all_data_copy["MathScore"], color="Red")

plt.subplot(132)
sns.regplot(x=all_data_copy["NrSiblings"], y=all_data_copy["MathScore"], color="Green")

plt.subplot(133)
sns.regplot(x=all_data_copy["WritingScore"], y=all_data_copy["MathScore"], color="Blue")

plt.tight_layout()
plt.show()

"""**Grafiklerin açıklaması**;

 MathScore hedef değişkeni ile diğer değişkenler (ReadingScore, NrSiblings, WritingScore) arasındaki ilişkileri(pozitif, negatif veya ilişkisizlik) görselleştirmek için **regresyon grafikleri** (**regression plots**) oluşturalım.

 -**Amacımız**, bu değişkenler ile hedef değişken arasındaki doğrusal ilişkiyi anlamak ve ilişkiyi güçlendiren bir çizgi ile görselleştirmektir.

 -Görselleştirme, değişkenler arasında anlamlı bir ilişki olup olmadığını belirlemeye yardımcı olur. Grafikler, hangi değişkenlerin hedef değişken üzerinde daha güçlü bir etkiye sahip olduğunu anlamak için bize yol gösterir.

 **Sonuç**:

 **Buradan, ReadingScore ve WritingScore'un MathScore'ları güçlü bir şekilde etkileyebileceği sonucunu çıkarıyoruz.**

 *Güçlü İlişkiler: ReadingScore ve WritingScore, MathScore ile güçlü pozitif doğrusal ilişkiye sahiptir ve matematik başarısını etkileyen önemli faktörlerdir.

 *Zayıf İlişki: NrSiblings, MathScore ile belirgin bir ilişki göstermemektedir, bu nedenle tahmin için kullanışlı olmayabilir.

 ***Modelleme için: ReadingScore ve WritingScore, modelleme için önemli özellikler olarak kullanılabilir. NrSiblings ise modelden çıkarılabilir.**

**2- MathScore hedef değişkeni ile diğer kategorik değişkenler arasındaki ilişkiler:**
"""

# Veri setinde yer alan kategorik değişkenleri grafiklerle görselleştirme:

import seaborn as sns
import matplotlib.pyplot as plt

# Eksik değerleri doldurma:
all_data_copy = all_data_copy.fillna("Missing")

#Sütunların liste değişkenine aktarılması
column_list = cat_cols

# Satır ve sütun sayısını hesapla:
num_rows = (len(column_list) + 1) // 2
num_cols = 2

# Grafikleri oluşturma:
fig, axes = plt.subplots(num_rows, num_cols, figsize=(14, 15))

# Sütunlar üzerinde döngü:
for idx, column in enumerate(column_list):
    try:
        row = idx // num_cols
        col = idx % num_cols
        # Eksik değerleri grafikten çıkarma:
        filtered_data = all_data_copy[all_data_copy[column] != "Missing"]

        # Çubuklar için her kategoriye farklı renkler atama:
        sns.countplot(data=filtered_data, x=column, ax=axes[row, col], palette="viridis")
        axes[row, col].set_title(column)
        axes[row, col].set_xlabel('Values')
        axes[row, col].set_ylabel('Count')
    except Exception as e:
        print(f"Hata sütununda: {column}")
        print(e)

plt.tight_layout()
plt.show()

"""**Üstteki Grafiklerin Genel Yorumu:**

Bu grafikler; bize veri setinde yer alan değerleri görsel olarak ortaya koymaktadır.

Şimdi aşağıdaki grafiklerle bu değişkenlerin, tek tek matematik puanları ile arasındaki ilişkileri inceleyelim...
"""

#Matematik puanları ve cinsiyet arasındaki ilişki:

sns.boxplot(x='Gender', y='MathScore', data=all_data_copy, hue='Gender')
plt.title('Relationship between Gender and Math Score')

"""**Üstteki Grafiğin Yorumlanması:**

Matematikte erkek öğrencilerin, kız öğrencilerden daha iyi performans gösterdiğini grafikten çıkarıyoruz. Bu, daha yüksek medyan ve %25 lik puanlarla kendini göstermektedir.

"""

#Parent Education & Gender: Cinsiyet ve Ebeveyn eğitim düzeyi arasındaki ilişkiÇ

# 'Missing' değerleri filtreleme
filtered_data = all_data_copy[all_data_copy['ParentEduc'] != "Missing"]

# Grafik oluşturma
sns.countplot(data=filtered_data, x='Gender', hue='ParentEduc')
plt.title("Parent Education level, Male v Female")
plt.show()

"""**Üstteki Grafiğin Yorumlanması:**

Ebeveynlerin eğitim düzeyi iki cinsiyet arasında hemen hemen aynı olduğunu görmekteyiz. Lisansüstü eğitim düzeyinde hafif bir fark görülür, burada kız öğrencilerin, erkek öğrencilere kıyasla; lisansüstü eğitim derecesi almış daha fazla ebeveyni vardır diyebiliriz.

"""

#Wkly Study Hours(Haftalık çalışma saatleri) İle Mathscore ilişkisini İnceleme:

# 'Missing' değerleri filtreleme:
filtered_data = all_data_copy[all_data_copy['WklyStudyHours'] != "Missing"]

# Grafik oluşturma:
plt.figure(figsize=(15, 7))

# İlk boxplot:
plt.subplot(121)
sns.boxplot(x='WklyStudyHours', y='MathScore', data=filtered_data, hue='WklyStudyHours')
plt.title("MathScore range based on WklyStudyHours")

# İkinci boxplot:
plt.subplot(122)
sns.boxplot(y='WklyStudyHours', x='MathScore', data=filtered_data, hue='Gender')
plt.title("Gender-wise MathScore range based on WklyStudyHours")

plt.tight_layout()
plt.show()

"""**Üstteki Grafiklerin Yorumlanması:**

İki grafikten de şu sonucu çıkarılabiliriz:

Haftalık çalışma süresi ne kadar artarsa, bu her iki cinsiyetteki öğrencilerin de daha yüksek Matematik notu almalarını sağlar.
"""

#IsFirstChild İle Mathscore ilişkisini İnceleme:

# 'Missing' değerleri filtreleme:
filtered_data = all_data_copy[all_data_copy['IsFirstChild'] != "Missing"]

# Grafik oluşturma:
plt.figure(figsize=(15, 7))

# İlk boxplot:
plt.subplot(121)
sns.boxplot(x='IsFirstChild', y='MathScore', data=filtered_data, hue='IsFirstChild', width=0.4)
plt.title("MathScore range based on IsFirstChild")

# İkinci boxplot:
plt.subplot(122)
sns.boxplot(x='IsFirstChild', y='MathScore', data=filtered_data, hue='Gender', width=0.4)
plt.title("Gender-wise MathScore range based on IsFirstChild")

plt.tight_layout()
plt.show()

"""**Üstteki Grafiklerin Yorumlanması:**

Bundan, ilk çocuk olmanın MathScore üzerinde çok az etkisi olduğunu yani neredeyse etkisi olmadığı sonucunu çıkarıyoruz.
"""

#PracticeSport, ParentMaritalStatus, TestPrep, LunchType, EthnicGroup, TransportMeans değişkenleri İle Mathscore ilişkisini İnceleme:

to_plot = ["PracticeSport", "ParentMaritalStatus", "TestPrep", "LunchType", "EthnicGroup", "TransportMeans"]

# Çizilecek sütunların listesi:
column_list = to_plot

# Kaç satır ve sütun gerektiğini hesaplama:
num_rows = (len(column_list) + 1) // 2
num_cols = 2

# Alt grafiklerin oluşturulması:
fig, axes = plt.subplots(num_rows, num_cols, figsize=(14, 15))

# Her sütun için döngü:
for idx, column in enumerate(column_list):
    # 'Missing' değerlerini çıkar
    filtered_data = all_data_copy[all_data_copy[column] != "Missing"]

    # Satır ve sütun konumlarını belirleme:
    row = idx // num_cols
    col = idx % num_cols

    # Grafikleri oluşturma:
    sns.boxplot(data=filtered_data, y=column, x='MathScore', hue=f'{column}', ax=axes[row, col], width=0.4)
    axes[row, col].set_title(f"{column} ve MathScore Arasındaki İlişki")
    axes[row, col].set_xlabel(column)
    axes[row, col].set_ylabel('MathScore')

plt.tight_layout()
plt.show()

"""**Üstteki Grafiklerin Yorumlanması:**

-Spor yapan öğrenciler, spor yapmayanlara göre matematikte daha iyi performans gösteriyor.

-Ebeveynleri evli olan öğrenciler, ebeveyni evli olmayanlara göre biraz daha iyi performans gösteriyor.

-Test hazırlık kursuna giden öğrenciler(Testprep) gitmeyenlere göre nispeten daha iyi performans gösteriyor.

-Çarpıcı bir sonuç olarak; standart öğle yemeği yiyen öğrenciler, indirimli/ücretsiz öğle yemeği yiyenlere göre Matematikte çok daha iyi performans gösteriyor.

-Etnik Grup E'den öğrenciler, kaydedilen diğer etnik gruplardan meslektaşlarına kıyasla Matematikte daha iyi performans gösteriyor.

-Okul otobüsüne binen öğrenciler, özel araç kullananlara göre Matematikte biraz daha iyi performans gösteriyorlar.

### **Veri Ön İşleme:**

Eksik değerler, aykırı değerler ve hatalı girişleri belirleme ve bunları uygun olan şekilde yeniden düzenleme, doldurma işlemleri.

**Önce veri setindeki sütunlarda yer alan değişkenlerin veri tiplerini yazdıralım:**
"""

all_data_copy.dtypes

"""**Hangi sütunların eksik değerlere sahip olduğunu belirleme işlemi ve o sütunların veri tiplerini yazdırma:**"""

for col in all_data_copy.columns:
    print(f"{col}: {all_data_copy[col].unique()}")

"""**Sonuçta;**

 Eksik değerlere sahip sütunlar: missing olarak görünüyor. Bu, veri setinde **NaN** olarak tanımlanmış eksik değerler bulunmadığını bize gösteriyor. Eksik değerler başka bir formatta (örneğin, "Missing", boş string "" veya başka bir özel değer) saklanıyor olabilir. Bunu bulmak için yukarıdaki kodu kullandım. Eksik değerlerin **Missing** olduğunu görüntüledim.
"""

#Eksik değerlere sahip sütunları bulma:

# 'Missing' veya boş string değerlerini NaN ile değiştirme:
all_data_copy.replace(["Missing", ""], pd.NA, inplace=True)

# Eksik değerlere sahip sütunları kontrol etme ve yazdırma:
null_cols = [col for col in all_data_copy.columns if all_data_copy[col].isnull().any()]

# Eksik değerlerin sayısı ve veri türlerini yazdırma:
for col in null_cols:
    print(f"{col}: Eksik değer sayısı = {all_data_copy[col].isnull().sum()}, Veri türü = {all_data_copy[col].dtype}")

print("\nEksik değerlere sahip sütunlar:", null_cols)

"""**Üstteki kodla**:

Eksik değerlere sahip olan sütunları ve eksik değer sayılarını yazdırdım. 'Missing' veya boş string değerlerini NaN ile değiştirdim.
"""

# Her sütundaki benzersiz değerleri yazdırma:

for col in null_cols:
    print(all_data_copy[col].value_counts())

"""**Veri setinin ilk 20 satırını görüntüleyelim:**"""

import numpy as np

# <NA> değerlerini NaN ile değiştirme:
all_data_copy = all_data_copy.replace({pd.NA: np.nan})

# Değişikliğin kontrol edilmesi:
all_data_copy.head(20)

"""**Eksik Değerlerin İşlenmesi:**

Eksik değerleri sütun türüne uygun şekilde doldurarak veri setini eksik değerlerden arındıralım:

Sütunlardaki: null veya NaN değerler
"""

# Eksik değerlere sahip sütunların işlenmesi:

# Eksik değerlere sahip sütunlarda döngüye alma:
for col in null_cols:
    if all_data_copy[col].dtype == 'object':
        # 'none' değerlerini 'Bilinmiyor' ile değiştirme:
        all_data_copy[col].replace('none', 'Bilinmiyor', inplace=True)
        # NaN değerlerini 'VeriYok' ile doldur
        all_data_copy[col].fillna('VeriYok', inplace=True)
    else:
        # Sayısal sütunlar için sütunun medyanını hesaplama:
        col_median = all_data_copy[col].median()
        # NaN değerlerini medyan ile doldurma:
        all_data_copy[col].fillna(col_median, inplace=True)

# Eksik değerler işlendikten sonra veri çerçevesini yazdırma:
print("Eksik değerler işlendi:")
print(all_data_copy)

"""**Eksik Değerleri Kontrol Etme ve Görselleştirme:**"""

# Eksik değerlerin kontrol edilmesi ve görselleştirme:

msno.bar(figsize=(16, 7), df=all_data_copy, color="blue")
plt.title("Veri eksiksizliğini gösteren çubuk grafik")

"""**Üstteki grafikle yaptığımız görselleştirmede** verilerimizde eksik değer olmadığını görebiliyoruz."""

#Şimdi ilk birkça satırı görüntüleyelim:

all_data_copy.head()

"""**Yukarıda yaptığımız "Keşifsel Veri Analizi (Exploratory Data Analysis, EDA)" ile** bu özniteliklerden, öğrenci performansı veya diğer önemli sonuçlarla ilişkilendirilmesinin faydalı olabileceğini bizlere gösterdiği öznitelikleri belirlemiş olduk.

**Yani modelleme veya sonuçlar üzerinde etkili olabilecek bazı önemli sütunları (özellikler) belirledim.**

Bunlar şu şekildedir:  

-ReadingScore

-WritingScore

-PracticeSport  

-LunchType  

-TestPrep  

-TransportMeans

-WklyStudyHours

-EthnicGroup

-Gender

-ParentMaritalStatus
"""

#import required dependencies
from sklearn.preprocessing import OrdinalEncoder

"""**Kategorik özellikleri (string) sayısal değerlere dönüştürerek, modelleme ve analizde kullanılabilir hale getirme işlemleri:**

OrdinalEncoder: Kategorik verileri her kategoriye bir sıra numarası atayarak sayısal değerlere dönüştüren bir araçtır (örneğin, "Male" -> 0, "Female" -> 1 gibi ).

Veri setimizdeki kategorik değişkenleri **Ordinal Encoding** yöntemiyle **sayısal değerlere dönüştürelim:**

-Kategorik sütunları (string) sayısal değerlere çevirelim.

-Encode edilmiş sütunları orijinal veri çerçevesiyle birleştirelim.

-Son olarak modelleme veya analiz için uygun hale getirelim.
"""

# Encode edilecek özelliklerin bir listesini oluşturalım:

features = ['PracticeSport', 'ParentMaritalStatus',
            'LunchType', 'TestPrep', 'TransportMeans', 'WklyStudyHours',
            'EthnicGroup', 'Gender']

# Orijinal sütun adlarını saklama:
original_col_names = all_data_copy[features].columns.tolist()

# OrdinalEncoder'ı başlatma:
encoder = OrdinalEncoder()
# Encode işlemini veri üzerinde uygulama ve dönüştürme işlemi:
df_encoded = pd.DataFrame(encoder.fit_transform(all_data_copy[features]),
                          columns=original_col_names)

# Orijinal ve encode edilmiş DataFrame'lerin indekslerini sıfırlama:
all_data_copy.reset_index(drop=True, inplace=True)
df_encoded.reset_index(drop=True, inplace=True)

# Encode edilmiş sütunları orijinal DataFrame ile birleştirme işlemi:
df_final = pd.concat([all_data_copy.drop(columns=features), df_encoded], axis=1)

print("Orijinal DataFrame:")
print(all_data_copy)
print("\nOrdinal encoding sonrası DataFrame:")
print(df_final)

#Şimdi de yukarıdaki işlemle birlikte ilk 20 satırın son halini görüntüleyelim:
df_final.head(20)

"""**Şimdi veri setindeki tüm sütunların** benzersiz değerlerin sayımını (frekansını) alalım ve veri setindeki dağılımını kontrol edelim. Özellikle kategorik verilerdeki encode işlemini doğrulamak veya veri dağılımlarını incelemek için bunu yapıyoruz."""

# Değişikliklerimizi inceleyelim:
for col in df_final.columns:
  # Her sütundaki benzersiz değerlerin sayısını yazdıralım:
    print(df_final[col].value_counts())
  # Sütunlar arasında boşluk eklemek için yeni bir satır yazdıralım:
    print("\n")

"""Veri setimizin **son durumdaki** satır ve sütun sayısına bakalım:"""

df_final.shape

"""### **Veri Setini Bölme İşlemi:**"""

#Hedef değişkeni ve öznitelikleri tanımlama:
X = df_final[features + ['ReadingScore', 'WritingScore']]
y = df_final['MathScore']

# Veri setini, test, doğrulama ve eğitim için bölme
train_ratio = 0.7
val_ratio = 0.15
test_ratio = 0.15

# Veri setini eğitim ve geçici setlere ayıralım:
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=1 - train_ratio, random_state=42
)

# Geçici kümeyi doğrulama ve test kümelerine bölelim:
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=test_ratio / (test_ratio + val_ratio), random_state=42
)

# Ortaya çıkacak bu sınıfların boyutlarını yazdıralım
print(f"Train set size: {len(X_train)}")
print(f"Validation set size: {len(X_val)}")
print(f"Test set size: {len(X_test)}")

"""### **2- MODELLEME VE EĞİTİM :**

**Lineer Regresyon, Random forest Regresörü ve Karar Ağacı Regresörü modellerini eğitelim**, doğrulama verileri üzerinde tahmin yaptıralım ve her bir **modelin Ortalama Mutlak Hata (MAE) değerini hesaplayarak** performans karşılaştırmasını görelim:
"""

print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_val shape: {X_val.shape}")
print(f"y_val shape: {y_val.shape}")

X_train = X_train.fillna(X_train.mean())
y_train = y_train.fillna(y_train.mean())
X_val = X_val.fillna(X_val.mean())
y_val = y_val.fillna(y_val.mean())

# İlk eğitim aşaması
from sklearn.tree import DecisionTreeRegressor

# Lineer regresyon için
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)  # Modeli eğitim verileriyle eğitme
linear_pred = linear_model.predict(X_val)  # Doğrulama verileri üzerinde tahmin yapma
print("MAE Linear reg:", mean_absolute_error(y_val, linear_pred))  # MAE'yi yazdırma

# Random forest regressor (rastgele orman regresörü) için
forest_model = RandomForestRegressor(random_state=42)
forest_model.fit(X_train, y_train)  # Modeli eğitim verileriyle eğitme
forest_pred = forest_model.predict(X_val)  # Doğrulama verileri üzerinde tahmin yapma
print("MAE Random Forest reg:", mean_absolute_error(y_val, forest_pred))  # MAE'yi yazdırma

# Karar ağacı regresörü için
tree_model = DecisionTreeRegressor(random_state=42)
tree_model.fit(X_train, y_train)  # Modeli eğitim verileriyle eğitme
tree_pred = tree_model.predict(X_val)  # Doğrulama verileri üzerinde tahmin yapma
print("MAE Decision Tree reg:", mean_absolute_error(y_val, tree_pred))  # MAE'yi yazdırma

"""**Ortalama Mutlak Hata (MAE) değerleri, üç farklı regresyon modelinin performansını karşılaştırmak için kullanılır.**

MAE, modelin tahmin ettiği değerler ile gerçek değerler arasındaki mutlak farkların ortalamasını alarak hesaplanır; bu değer ne kadar düşükse, modelin tahminleri gerçek değerlere o kadar yakındır.

**Lineer Regresyon: MAE = 4.5588**

**Random Forest Regressor: MAE = 4.7053**

**Decision Tree Regressor: MAE = 6.4474**

**Bu sonuçlara göre, Lineer Regresyon modelimiz en düşük MAE değerine sahip olup, tahminlerinde diğer modellere göre daha başarılıdır.**

Random Forest Regressor'ın MAE değeri Lineer Regresyon'a yakın olsa da, biraz daha yüksektir, bu da tahminlerinin Lineer Regresyon'dan biraz daha az iyi olduğunu gösterir. Decision Tree Regressor ise en yüksek MAE değerine sahip olup, bu üç model arasında en düşük performansı sergilemektedir.

### **Modelleri Cross Validation ile Performans Değerlendirme:**
"""

from sklearn.model_selection import cross_val_score

# Aşırı öğrenmeyi (overfitting) azaltmak için çapraz doğrulama (cross-validation) uygulayalım.

# Modellerin örnekleri:
linear_model_2 = LinearRegression()
forest_model_2 = RandomForestRegressor(random_state=42)
tree_model_2 = DecisionTreeRegressor(random_state=42)

# Model listesi:
models = [linear_model_2, forest_model_2, tree_model_2]

# Her model için döngü oluşturalım ve çapraz doğrulama uygulayalım:
for model in models:
    # 4 katmanlı (fold) çapraz doğrulama yapalım (katman sayısı ayarlanabilir)
    scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=4)

    # Negatif ortalama mutlak hata (MAE) skorlarının ortalamasını hesaplama:
    mae_mean = -scores.mean()

    # Model için ortalama mutlak hatayı yazdırma:
    model_name = model.__class__.__name__
    print(f"MAE {model_name}: {mae_mean}")

"""**Sonuç üsttekilerle kıyaslanınca:**
Random Forest ve Decision Tree regresyon modellerinde biraz daha gelişmiş bir model performansı görebiliyoruz. Linear Regressor'daki performansın az da olsa düştüğünü farkediyoruz.

Birden fazla ayarlamadan sonra, her modelin performansının en güvenilir tahmini için optimum sayı olarak çapraz doğrulamayı 4 kat olarak belirledim.

**Sonuçta**, Genel olarak Lineer Regresyon modelimiz en düşük MAE değerine sahip olup, tahminlerinde diğer modellere göre daha başarılıdır.

### **Hiperparametre Ayarı**
"""

!pip install optuna
import optuna

# Optuna için optimize edilecek bir hedef fonksiyonu tanımlayalım:
def objective(trial):
    # Hiperparametre arama alanını tanımlayalım:
    # RandomForestRegressor için 'n_estimators' ve 'max_depth' hiperparametrelerini ayarlama:
    n_estimators = trial.suggest_int('n_estimators', 10, 100)  # Ağaç sayısı aralığı
    max_depth = trial.suggest_int('max_depth', 2, 20)          # Maksimum derinlik aralığı

    # Önerilen hiperparametrelerle modellerin örneklerini oluşturma:
    linear_model_3 = LinearRegression()
    forest_model_3 = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)
    tree_model_3 = DecisionTreeRegressor(random_state=42)

    # Model listesi
    models = [linear_model_3, forest_model_3, tree_model_3]

    # Her model üzerinde döngü oluşturma ve çapraz doğrulama uygulama:
    for model in models:
        # 4 katmanlı (fold) çapraz doğrulama yapmak (katman sayısı farklı ayarlanabilir)
        scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=4)

        # Negatif ortalama mutlak hata (MAE) skorlarının ortalamasını hesaplmaÇ:
        mae_mean = -scores.mean()

        # Model için ortalama mutlak hatayı yazdırma:
        model_name = model.__class__.__name__
        print(f"MAE {model_name}: {mae_mean}")

        # Optuna için hedef değer olarak ortalama mutlak hatayı döndürme:
        return mae_mean

# Optuna çalışması oluşturma:
study = optuna.create_study(direction='minimize')  # Amaç, MAE'yi minimize etmek.

# Hedef fonksiyonu optimize etmek:
study.optimize(objective, n_trials=100)  # 100 farklı deneme gerçekleştiririz.

# En iyi hiperparametreleri ve hedef değerleri yazdırmak:
best_params = study.best_params  # En iyi hiperparametreler
best_mae = study.best_value      # En iyi MAE değeri
print("En İyi Hiperparametreler:", best_params)
print("En İyi MAE:", best_mae)

"""Verimliliği nedeniyle hiperparametre ayarı için optuna kullandık. Süreci kolaylaştırmak için çapraz varyasyon hedef fonksiyonu içerisindedir.

**Üstteki sonuçlardan, Doğrusal Regresyonun hala en iyi performans gösteren model olduğunu görüyoruz.**

**XGBoot Regressor Modeli Eğitimi:**
"""

#XGBoot Regressor ile model eğitimi:

from xgboost import XGBRegressor

xg_model = XGBRegressor()
xg_model.fit(X_train, y_train)

xg_pred = xg_model.predict(X_val)
print("MAE XGBoost Regressor:", mean_absolute_error(xg_pred, y_val))

"""**Bu son modelin sonucunda** MAE'de hafif bir iyileşme görüyoruz; yaklaşık 0,1'lik bir azalma. Herhangi bir olası iyileştirme varsa bunu keşfetmek için Hiperparametre Optunayı kullanıyoruz:

**XGBoot Regressor Modeli Üzerinde Optuna ile Hiperparametre Ayarı :**
"""

from xgboost import XGBRegressor
import optuna
from sklearn.metrics import mean_absolute_error

# Optuna için objective fonksiyonunun tanımlanması:
def objective(trial):
    # Hiperparametre arama alanının tanımlanması:
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'early_stopping_rounds': 5  # early_stopping_rounds parametresinin burada belirtilmesi:
    }

    # Önerilen hiperparametrelerle XGBRegressor modelinin oluşturulması:
    my_model = XGBRegressor(**params, n_jobs=4)

    # Modelin eğitim verisi üzerinde eğitilmesi:
    my_model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        verbose=False
    )

    # Doğrulama verisi üzerinde tahmin yapılması:
    predictions = my_model.predict(X_val)

    # Ortalama Mutlak Hata (MAE) metriğinin hesaplanması:
    mae = mean_absolute_error(y_val, predictions)

    # Optuna'nın minimize edeceği MAE değerinin döndürülmesi:
    return mae

# Optuna çalışmasının oluşturulması:
study_2 = optuna.create_study(direction='minimize')

# Objective fonksiyonunun optimize edilmesi
study_2.optimize(objective, n_trials=100)

# En iyi hiperparametrelerin ve en düşük MAE değerinin alınması:
best_params = study_2.best_params
best_mae = study_2.best_value

print("En İyi Hiperparametreler:", best_params)
print("En Düşük MAE:", best_mae)

"""**Hiperparametre optimizasyonundan sonra;**

İlk MAE değeri 4.4991 iken, ikinci MAE değeri 4.3393'e düşmüştür. Bu, yaklaşık olarak %3.46'lık bir iyileşme anlamına gelir.

**Dolayısıyla XGBoost Regressor'un ileriye dönük en iyi model olduğunu görürüz.**

## **3- FİNAL SONUÇLAR:**

Modellerin Test Sonuçları:
"""

# Optuna tarafından bulunan en iyi hiperparametrelerle bir XGB Regressor Modeli örneği oluşturalım:
best_params = study_2.best_params
xg_model_final = XGBRegressor(**best_params, n_jobs=4)

# Modeli, birleştirilmiş eğitim ve doğrulama verileri üzerinde eğitme:
xg_model_final.fit(
    pd.concat([X_train, X_val]),  # Eğitim ve doğrulama özelliklerini birleştirme
    pd.concat([y_train, y_val])   # Eğitim ve doğrulama hedeflerini birleştirme
)

# Test verileri üzerinde tahminler yapma:
test_predictions = xg_model_final.predict(X_test)

# Test verileri üzerinde Ortalama Mutlak Hata (MAE)'yi hesaplama:
test_mae_xg = mean_absolute_error(y_test, test_predictions)

# Test MAE'yi yazdırarak modelin performansını değerlendirme:
print("Test MAE XGBoostRegressor:", test_mae_xg)

#Seçilen diğer regresörlerle karşılaştırıldığında XGBoostRegressor'un performansının görselleştirilmesi

#Random forest regressor için en iyi parametreler:
best_params_forest = study_2.best_params

linear_model_final = LinearRegression()
forest_model_final = RandomForestRegressor()

final_models = [linear_model_final, forest_model_final]
final_maes = [test_mae_xg]

for model in final_models:
    model.fit(
    pd.concat([X_train, X_val]),  # Eğitim ve doğrulama özelliklerini birleştirme
    pd.concat([y_train, y_val])   # Eğitim ve doğrulama hedeflerini birleştirme
)

    # Test verileri üzerinde tahminler yapma:
    test_predictions = model.predict(X_test)

    # Test verileri üzerinde Ortalama Mutlak Hata (MAE)'yi hesaplama:
    test_mae = mean_absolute_error(y_test, test_predictions)

    # final "test_mae" listesine ekleme:
    final_maes.append(test_mae)

    # Test MAE'yi yazdırarak modelin performansını değerlendirme:
    print(f"Test MAE {model}:, {test_mae}")

"""### **Modellerin Performansını Görselleştirme:**

**Model Performans Karşılaştırması - (MAE - Mean Absolute Error - Ortalama Mutlak Hata Değerleri):**

1-	XGBoost	4.425080299377441

2-	Linear Regression	4.621658229399975

3-	Random Forest	4.77903256473083
"""

#Test MAE performansını görselleştirme:
model_names = ["XGBoost", "Linear Regression", "Random Forest"]
plt.bar(model_names, final_maes)
plt.xlabel("Model")
plt.ylabel("Test MAE")
plt.title("Eğitilen regresyon modelleri için test MAE'sinin karşılaştırılması")
plt.show()

"""**Sonuç Olarak; XGBoost Modeli Gerçek ve Tahmin Edilen Değerler Grafiği:**"""

import matplotlib.pyplot as plt

# XGBoost Modeli Test verisi üzerindeki tahminler:
y_pred = xg_model_final.predict(X_test)

# Dağılım grafiği:
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # y = x doğrusu
plt.xlabel('Gerçek Değerler')
plt.ylabel('Tahmin Edilen Değerler')
plt.title('XGBoost Modeli Gerçek ve Tahmin Edilen Değerler Grafiği')
plt.show()

"""Gerçek ve tahmin edilen değerlerin dağılım grafiğine
bakacak olursak;

-Modellerimize ait tahminlerin gerçek değerlere ne
kadar yakın  olduğunu bize gösteriyor.

-Noktalar  y = x doğrusu etrafında
yoğunlaşması, modelin yüksek doğrulukla tahmin
 yaptığını belirtiyor.

### **Tüm Modeller İçin Confusion Matrix Çizdirelim:**

Her model için ayrı ayrı Confusion Matrix çizdirdik.
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# XGBoost, RandomForest ve Linear Regression modelleri ile test verisi üzerinde tahmin yapma
xgb_prob = xg_model_final.predict(X_test)
rf_prob = forest_model_final.predict(X_test)
lr_prob = linear_model_final.predict(X_test)

# Eşik değerine göre sınıflandırma yap
threshold = 50  # Sınıflandırma için eşik değeri (örneğin, 50'nin üzerini pozitif kabul edebiliriz)
y_pred_class_xgb = (xgb_prob >= threshold).astype(int)
y_pred_class_rf = (rf_prob >= threshold).astype(int)
y_pred_class_lr = (lr_prob >= threshold).astype(int)

# Confusion Matrix oluştur
cm_xgb = confusion_matrix(y_test >= threshold, y_pred_class_xgb)
cm_rf = confusion_matrix(y_test >= threshold, y_pred_class_rf)
cm_lr = confusion_matrix(y_test >= threshold, y_pred_class_lr)

# Confusion Matrix'i görselleştir
plt.figure(figsize=(15, 5))

# XGBoost Confusion Matrix
plt.subplot(1, 3, 1)
disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cm_xgb, display_labels=['Negatif', 'Pozitif'])
disp_xgb.plot(cmap='Blues', ax=plt.gca())
plt.title("XGBoost Confusion Matrix")

# Random Forest Confusion Matrix
plt.subplot(1, 3, 2)
disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=['Negatif', 'Pozitif'])
disp_rf.plot(cmap='Greens', ax=plt.gca())
plt.title("Random Forest Confusion Matrix")

# Linear Regression Confusion Matrix
plt.subplot(1, 3, 3)
disp_lr = ConfusionMatrixDisplay(confusion_matrix=cm_lr, display_labels=['Negatif', 'Pozitif'])
disp_lr.plot(cmap='Reds', ax=plt.gca())
plt.title("Linear Regression Confusion Matrix")

plt.tight_layout()
plt.show()

"""**Sonuçların Grafiklerle Yorumlanması:**

-XGBoost Regresor modelinin en iyi model olduğunu görüyoruz, çünkü en yüksek doğru pozitif oranına ve en düşük yanlış negatif oranına sahiptir. Yanlış pozitif oranı da oldukça düşüktür, bu da modelin genel olarak iyi genelleştirme sağladığını gösterir.

-Linear Regression modeli ve Random Forest modeli, genel olarak XGBoost'a göre  daha düşük doğruluk performansı göstermektedirler ve yanlış negatif ve pozitif oranı daha yüksektir.

Alttaki tabloyu worde ekleteceğim resim olarak:
Model	Doğru Pozitif (TP)	Yanlış Pozitif (FP)	Doğru Negatif (TN)	Yanlış Negatif (FN)
XGBoost	3823	174	466	134
Random Forest	3811	180	460	146
Linear Regression	3821	184	456	136

### **Tüm Modeller İçin ROC Eğrisini Çizdirelim:**

XGBoost, RandomForest ve LinearRegression modelleri için ROC eğrisini çizdirdik. Regresyon modelleri doğrudan olasılık döndürmediğinden, çıktıları belirli bir eşik değeri ile sınıflandırmaya dönüştürdük.
"""

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np

# Modellerin tahminlerini al
xgb_prob = xg_model_final.predict(X_test)
rf_prob = forest_model_final.predict(X_test)
lr_prob = linear_model_final.predict(X_test)

# Regresyon çıktıları sürekli olduğundan, ikili sınıflara dönüştürmek için bir eşik belirledim.
threshold = 50  # Örneğin, 50'nin üzeri 1 (başarılı), altı 0 (başarısız) olarak değerlendirilir.

# Sınıflandırma yapmak için eşik değerine göre çıktıların sınıflandırılmasını sağladık:
y_pred_xgb = (xgb_prob >= threshold).astype(int)
y_pred_rf = (rf_prob >= threshold).astype(int)
y_pred_lr = (lr_prob >= threshold).astype(int)

# ROC eğrisi için fpr (False Positive Rate), tpr (True Positive Rate) hesaplamak:
fpr_xgb, tpr_xgb, _ = roc_curve(y_test >= threshold, xgb_prob)
fpr_rf, tpr_rf, _ = roc_curve(y_test >= threshold, rf_prob)
fpr_lr, tpr_lr, _ = roc_curve(y_test >= threshold, lr_prob)

# AUC (Alan Altındaki Eğri) hesaplama:
roc_auc_xgb = auc(fpr_xgb, tpr_xgb)
roc_auc_rf = auc(fpr_rf, tpr_rf)
roc_auc_lr = auc(fpr_lr, tpr_lr)

# ROC Eğrisini Çizdirme:
plt.figure(figsize=(10, 7))
plt.plot(fpr_xgb, tpr_xgb, color='blue', lw=2, label=f'XGBoost (AUC = {roc_auc_xgb:.2f})')
plt.plot(fpr_rf, tpr_rf, color='green', lw=2, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')
plt.plot(fpr_lr, tpr_lr, color='red', lw=2, label=f'Linear Regression (AUC = {roc_auc_lr:.2f})')

# Rastgele model için diyagonal çizgi Oluşturma:
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate (Yanlış Pozitif Oranı)')
plt.ylabel('True Positive Rate (Doğru Pozitif Oranı)')
plt.title('ROC Curve - Model Karşılaştırması')
plt.legend(loc='lower right')
plt.grid()
plt.show()

"""**Sonuçların Grafikle Yorumlanması:**

**ROC** (Receiver Operating Characteristic) **Eğrisi** ile, üç farklı modelin (XGBoost, Random Forest ve Linear Regression) sınıflandırma performansını karşılaştırmaktayız. **ROC eğrisi**, modellerin True Positive Rate (Doğru Pozitif Oranı) ile False Positive Rate (Yanlış Pozitif Oranı) arasındaki ilişkisini bize gösterir.

**En iyi model: XGBoost ve Linear Regression modelleri**, AUC = 0.97 ile en iyi sınıflandırma performansını göstermektedir.
**Random Forest:** AUC değeri biraz daha düşük olmasına rağmen, genel olarak başarılı bir modeldir.

**Sonuç olarak;** XGBoost veya Linear Regression modeli daha iyi bir seçim olabilir, ancak diğer faktörleri yani, model karmaşıklığını, hesaplama maliyetini, yorumlanabilirliğini de göz önünde bulundurmak  sonuçlar açısından daha etkili olacaktır.
"""